---
title: "CaseStudyUnit6"
author: "Jean Jecha, Manjula Kottegoda, Sharon Teo, Jessica Wheeler"
date: "October 16, 2017"
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Introduction
Real Time Location System (RTLS) technique is used to determine relative or exact locations of a sensor at a given time. This case study involves Real Time Location System (RTLS) data collect from CRAWDAD <https://www.crawdad.org/> that originated in a University of Mannheim (See Figure 1) for Floor plan of the readings. 

![Figure 1]( https://s3.us-east-2.amazonaws.com/buk10102017/Fig1.1.PNG)

The data used in the case study consists of two datasets that are named ‘offline’ and ‘online’. ‘Offline’ data is used for training the models and is collected from of 166 points spaced 1 meter apart in the hallway of the floor plan (grey circles in image above.) The ‘online’ data is for testing and predicting and are collected from 60 location from the same floor (black circles in image above.)

In this case study we will be using a statistical method known as the k-nearest neighbor to estimate the location of a device from the strength of the signal detected between the device and serveral access points. Our dataset contains training data where the signal is measured to several access points from known positions throughout the building. When we get new observations from an unknown location, we find the observation from our training data that is closest to this new observation. This method allows us to predict the position of the new observation.

The variables in the dataset are t for timestamp in milliseconds, id for MAC address of scanning device, pos for the physical coordinate of the scanning device, degree for orientation of the user carrying the scanning device in degrees and finally, MAC for the MAC address of a corresponding peer.

In this case study we will be using a statistical method known as the k-nearest neighbor to estimate the location of a device from the strength of the signal detected between the device and serveral access points. Our dataset contains training data where the signal is measured to several access points from known positions throughout the building. When we get new observations from an unknown location, we find the observation from our training data that is closest to this new observation. This method allows us to predict the position of the new observation.

The variables in the dataset are t for timestamp in milliseconds, id for MAC address of scanning device, pos for the physical coordinate of the scanning device, degree for orientation of the user carrying the scanning device in degrees and finally, MAC for the MAC address of a corresponding peer.

#Raw Data Processing

Read in the data as a string character vector called 'txt'. Then search for lines that start with a hashtag
```{r}

options(digits = 2)

txt = readLines("http://rdatasciencecases.org/Data/offline.final.trace.txt")
sum(substr(txt, 1, 1) == "#")
```

```{r}
length(txt)
```

There are 5,312 comment lines that start with a hashtag. Next we look at the number of lines in the file. There are 151,392 lines in the file. According to the documentation we expect there to be 146,080 lines. The defference between 151,392 and 146,080 is 5,312, which is what we expected


Next, we are going to manipulate the data. Notice how the main data elements are seperated by a semicolon.  Let's see how the semicolon splits the fourth line, which is the first line that is not a comment
```{r}
strsplit(txt[4], ";")[[1]]
```
We can also split the character vector by a ';', '=' or ',' character and define the vector as 'tokens'. The first 10 elements of tokens give information about the hand-held device:

```{r}
tokens = strsplit(txt[4], "[;=,]")[[1]]
tokens
tokens[1:10]
```

Then we can extract the values for the 2nd, 4th, 6-8th and 10th lines of the variables time, id, position and x,y,z orientation.

```{r}
tokens[c(2, 4, 6:8, 10)]
```
The remainng values in the split vector are the recorded signals within the observation
```{r}
tokens[ - ( 1:10 ) ]
```
The results above show a 4-column data frame that shows the MAC address, signal, channel, and device type. We can now build a 4-column matrix called "tmp" and then bind these columns with the values from the first 10 entries using the function cbind
```{r}
tmp = matrix(tokens[ - (1:10) ], ncol = 4, byrow = TRUE)
mat = cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow = nrow(tmp),
                   ncol = 6, byrow = TRUE), tmp)
```{r}
tmp
```
The information about the device, ie time, id, position and x,y,z orientation is now combined with the recorded signals, ie MAC address, signal, channel and device type
```{r}
mat
```
There should be 11 rows, one for each MAC address and 10 columns where the first 6 columns represent the information for the handheld device and the last 4 columns representing the recorded signals 
```{r}
dim(mat)
```
Now we can create a function called "processLine" so we can repeat this operation for each row
```{r}
processLine = function(x) {
  tokens = strsplit(x, "[;=,]")[[1]]
  tmp = matrix(tokens[ - (1:10) ], ncol = 4, byrow = TRUE)
  cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow = nrow(tmp),
               ncol = 6, byrow = TRUE), tmp)
}
```
Let's apply our function to several lines using lapply. We start at the 4th line because the first three lines are comments and end on the 20th line. The result is a list of 17 matrices
```{r}
tmp = lapply(txt[4:20], processLine)
```
We use sapply to determine how many signals were detected at each point
```{r}
sapply(tmp, nrow)
```
To stack the matrices together we use the function do.call()

```{r}
offline = as.data.frame(do.call("rbind", tmp))
dim(offline)
```
```{r}
lines = txt[ substr(txt, 1, 1) != "#" ]
tmp = lapply(lines, processLine) # This line generates the error
```
We get a warning message. We can trace the error by setting the option to handle errors
```{r}
options(error = recover, warn = 2)
```
The error is due to a missing signal value. This observation can be deleted to fix the error. We change our function to return NULL if the tokens vector only has 10 elements. Here is our revised function 

```{r}
processLine = function(x) {
  tokens = strsplit(x, "[;=,]")[[1]]
  
  if (length(tokens) == 10) 
    return(NULL)
 
  tmp = matrix(tokens[ - (1:10) ], , 4, byrow = TRUE)
  cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow(tmp), 6, 
               byrow = TRUE), tmp)
}

tmp = lapply(lines, processLine)
offline = as.data.frame(do.call("rbind", tmp), 
                        stringsAsFactors = FALSE)

dim(offline)
```
This time we do not get an error message and we have over one million rows and 10 columns

# Cleaning the Data
To clean the data we first create variables with meaningful names and convert them to the proper numeric data type

```{r}
names(offline) = c("time", "scanMac", "posX", "posY", "posZ", "orientation", "mac", "signal", "channel", "type")


numVars = c("time", "posX", "posY", "posZ", 
            "orientation", "signal")

offline[ numVars ] =  lapply(offline[ numVars ], as.numeric)  # idempotent
offline = offline[ offline$type == "3", ]                     # idempotent
offline = offline[ , "type" != names(offline) ]               # idempotent
dim(offline)

offline$rawTime = offline$time
offline$time = offline$time/1000
class(offline$time) = c("POSIXt", "POSIXct")         # Use of "functional" assignment

unlist(lapply(offline, class))

summary(offline[, numVars])

summary(sapply(offline[ , c("mac", "channel", "scanMac")],
               as.factor))

offline = offline[ , !(names(offline) %in% c("scanMac", "posZ"))]  # Get rid of two columns

# Exploring Orientation
length(unique(offline$orientation))

plot(ecdf(offline$orientation))
```
The experiment was supposed to measure 8 orientations but the graph shows that this isn't the case. We should go ahead and round the orientation to the 8 equi-spaced angles. For example we will map an angle of 47.5 to 45 and 359.5 to 0 and so on. 
```{r}
pdf(file = "Geo_ECDFOrientation.pdf", width = 10, height = 7)
oldPar = par(mar = c(4, 4, 1, 1))
plot(ecdf(offline$orientation), pch = 19, cex = 0.3,
     xlim = c(-5, 365), axes = FALSE,
     xlab = "orientation", ylab = "Empirical CDF", main = "")
box()
axis(2)
axis(side = 1, at = seq(0, 360, by = 45))
par(oldPar)
dev.off()

pdf(file = "Geo_DensityOrientation.pdf", width = 10, height = 5)
oldPar = par(mar = c(4, 4, 1, 1))
plot(density(offline$orientation, bw = 2), 
 xlab = "orientation", main = "")
par(oldPar)
dev.off()
```

```{r}
roundOrientation = function(angles){
  refs = seq(0, by = 45, length = 9)
  q = sapply(angles, function(o) which.min(abs(o - refs)))
  c(refs[1:8], 0)[q]
}

offline$angle = roundOrientation(offline$orientation)

with(offline, boxplot(orientation ~ angle,
                      xlab = "nearest 45 degrees angle",
                      ylab = "orientation"))
```

The graph above shows that the new values have been rounded correctly to 0, 45, 90, 135, etc

#Exploring MAC Adresses

```{r}
c(length(unique(offline$mac)), length(unique(offline$channel)))
```
We find that there are 12 MAC addresses adn 8 channels. 
```

```{r}
table(offline$mac)
```
Using the table function we are able to check the counts of observations for the various MAC addresses. We see that the counts for the first and the last 2 MAC addresses are very low. Furthermore the 3rd and 5th MAC address counts look low. This implies that these observations were not near the testing area or only working for a short time during the measurement process. We decide to keep the records for the top 7 devices. 

```{r}
subMacs = names(sort(table(offline$mac), decreasing = TRUE))[1:7] # Get the 7 most common mac addresses
offline = offline[ offline$mac %in% subMacs, ]
```
Finally we create a table of counts for the remaining MAC X Channel combinations and confirm that there is one non-zero entry in each row
```{r}
# establish that macChannel and mac are redundant
macChannel = with(offline, table(mac, channel))     

apply(macChannel, 1, function(x) sum(x > 0))
```
Indeed there is a one to one correspondence between the MAC address and channel for the 7 devices
```{r}
offline = offline[ , "channel" != names(offline)]
```
#Exploring the Position of the Hand-Held Device

In this section we look at the postion variables posX and posY and investigate how many locations actually have data. We use the by() function to tally up the number of rows in our data frame for each unique (x,y) combination

```{r}
xlocDF = with(offline, 
              by(offline, posX, function(x) x))  

locDF = with(offline, 
             by(offline, list(posX, posY), function(x) x))  # for each value X and Y, return the data frame that matches
                                                            # posX and posY have to be *factors*
                                                            # But note that it takes the cartesian product of posX x posY, creating nulls

length(locDF)

# since this is a list, use sapply
sum(sapply(locDF, is.null))

locDF = locDF[ !sapply(locDF, is.null) ]

length(locDF)

locCounts = sapply(locDF, nrow)
locCounts  #166

# create a "map" of location counts
locCounts = sapply(locDF, 
                   function(df) 
                     c(df[1, c("posX", "posY")], count = nrow(df)))


class(locCounts)  # sapply created a matrix---why?

dim(locCounts)

locCounts[ , 1:8]

locCounts = t(locCounts)      # common occurence: transpose after running sapply

#pdf(file = "Geo_XYByCount.pdf", width = 10)
oldPar = par(mar = c(3.1, 3.1, 1, 1))
plot(locCounts, type = "n", xlab = "", ylab = "")     # first argument x, second y
text(locCounts, labels = locCounts[,3], cex = .8, srt = 45)
par(oldPar)
#dev.off()
```
The plot above shows the number of signals detected from all the access points. 110 signals were measured at 8 angles for each of the 6 access points for a total of 5280 recordings

Redo the preceding analysis in a concise function
```{r}
readData = 
  function(filename = 'http://rdatasciencecases.org/Data/offline.final.trace.txt', 
           subMacs = c("00:0f:a3:39:e1:c0", "00:0f:a3:39:dd:cd", "00:14:bf:b1:97:8a",
                       "00:14:bf:3b:c7:c6", "00:14:bf:b1:97:90", "00:14:bf:b1:97:8d",
                       "00:14:bf:b1:97:81"))
  {
    txt = readLines(filename)
    lines = txt[ substr(txt, 1, 1) != "#" ]
    tmp = lapply(lines, processLine)
    offline = as.data.frame(do.call("rbind", tmp), 
                            stringsAsFactors= FALSE) 
    
    names(offline) = c("time", "scanMac", 
                       "posX", "posY", "posZ", "orientation", 
                       "mac", "signal", "channel", "type")
    
     # keep only signals from access points
    offline = offline[ offline$type == "3", ]
    
    # drop scanMac, posZ, channel, and type - no info in them
    dropVars = c("scanMac", "posZ", "channel", "type")
    offline = offline[ , !( names(offline) %in% dropVars ) ]
    
    # drop more unwanted access points
    offline = offline[ offline$mac %in% subMacs, ]
    
    # convert numeric values
    numVars = c("time", "posX", "posY", "orientation", "signal")
    offline[ numVars ] = lapply(offline[ numVars ], as.numeric)

    # convert time to POSIX
    offline$rawTime = offline$time
    offline$time = offline$time/1000
    class(offline$time) = c("POSIXt", "POSIXct")
    
    # round orientations to nearest 45
    offline$angle = roundOrientation(offline$orientation)
      
    return(offline)
  }

offlineRedo = readData()

identical(offline, offlineRedo)

```



# Signal Strength Analysis
## Distribution of Signal Strength

```{r}
library(lattice)

#pdf(file = "Geo_BoxplotSignalByMacAngle.pdf", width = 7)
oldPar = par(mar = c(3.1, 3, 1, 1))
bwplot(signal ~ factor(angle) | mac, data = offline,                 # Note how | indicates panels
       subset = posX == 2 & posY == 12 
                & mac != "00:0f:a3:39:dd:cd", 
       layout = c(2,3))

par(oldPar)
#dev.off()

summary(offline$signal)

#pdf(file = "Geo_DensitySignalByMacAngle.pdf", width = 8, height = 12)
oldPar = par(mar = c(3.1, 3, 1, 1))

densityplot( ~ signal | mac + factor(angle), data = offline,         # Note how | indicates panels with +
             subset = posX == 24 & posY == 4 & 
                         mac != "00:0f:a3:39:dd:cd",
             bw = 0.5, plot.points = FALSE)

par(oldPar)

```
```{r}
#offline = offline[ offline$mac != "00:0f:a3:39:dd:cd", ]

offline$posXY = paste(offline$posX, offline$posY, sep = "-")

byLocAngleAP = with(offline, 
                    by(offline, list(posXY, angle, mac), 
                       function(x) x))

signalSummary = 
  lapply(byLocAngleAP,            
         function(oneLoc) {
           ans = oneLoc[1, ]
           ans$medSignal = median(oneLoc$signal)
           ans$avgSignal = mean(oneLoc$signal)
           ans$num = length(oneLoc$signal)
           ans$sdSignal = sd(oneLoc$signal)
           ans$iqrSignal = IQR(oneLoc$signal)
           ans
           })

signalSummary[[1]]

offlineSummary = do.call("rbind", signalSummary)         #another common re-shuffle, rbind after lapply

# what does do.call do?
# "argument list" (cf. xargs in unix)
# called a Variadic Function
# example: List(1,2,3,...)


#pdf(file = "Geo_BoxplotSignalSDByAvg.pdf", width = 10)
oldPar = par(mar = c(3.1, 3, 1, 1))

breaks = seq(-90, -30, by = 5)
bwplot(sdSignal ~ cut(avgSignal, breaks = breaks),
       data = offlineSummary, 
       subset = mac != "00:0f:a3:39:dd:cd",
       xlab = "Mean Signal", ylab = "SD Signal")
                                                       # How to interpret this chart? "Distribution" of signal

par(oldPar)
#dev.off()

#pdf(file = "Geo_ScatterMean-Median.pdf", width = 10)
oldPar = par(mar = c(4.1, 4.1, 1, 1))

with(offlineSummary,
     smoothScatter((avgSignal - medSignal) ~ num,
                   xlab = "Number of Observations", 
                   ylab = "mean - median"))
abline(h = 0, col = "#984ea3", lwd = 2)

lo.obj = 
  with(offlineSummary,
       loess(diff ~ num, 
             data = data.frame(diff = (avgSignal - medSignal),
                               num = num)))

lo.obj.pr = predict(lo.obj, newdata = data.frame(num = (70:120)))
lines(x = 70:120, y = lo.obj.pr, col = "#4daf4a", lwd = 2)

par(oldPar)
#dev.off()

```{r}
oneAPAngle = subset(offlineSummary, 
                    mac == subMacs[5] & angle == 0)


library(fields)
smoothSS = Tps(oneAPAngle[, c("posX","posY")], 
               oneAPAngle$avgSignal)

vizSmooth = predictSurface(smoothSS)

plot.surface(vizSmooth, type = "C")

points(oneAPAngle$posX, oneAPAngle$posY, pch=19, cex = 0.5)

surfaceSS = function(data, mac, angle = 45) {
  require(fields)
  oneAPAngle = data[ data$mac == mac & data$angle == angle, ]
  smoothSS = Tps(oneAPAngle[, c("posX","posY")], 
                 oneAPAngle$avgSignal)
  vizSmooth = predictSurface(smoothSS)
  plot.surface(vizSmooth, type = "C", 
               xlab = "", ylab = "", xaxt = "n", yaxt = "n")
  points(oneAPAngle$posX, oneAPAngle$posY, pch=19, cex = 0.5) 
}
parCur = par(mfrow = c(2,2), mar = rep(1, 4))

mapply(surfaceSS, mac = subMacs[ rep(c(5, 1), each = 2) ], 
       angle = rep(c(0, 135), 2),
       data = list(data = offlineSummary))
 
par(parCur)
```
Looking at the heat maps from left to right, we can see that the heat map smears up. This indicates that when the device is facing the emitter, we get a strong signal strength. When facing away, the signal gets weaker and the heat map looks more blurry. We can make the conclusion that the angle that the reading is taken will affect the signal strength.

```{r}
offlineSummary = subset(offlineSummary, mac != subMacs[2])

AP = matrix( c( 7.5, 6.3, 2.5, -.8, 12.8, -2.8,  
                1, 14, 33.5, 9.3,  33.5, 2.8),
            ncol = 2, byrow = TRUE,
            dimnames = list(subMacs[ -2 ], c("x", "y") ))

AP

diffs = offlineSummary[ , c("posX", "posY")] - 
          AP[ offlineSummary$mac, ]

offlineSummary$dist = sqrt(diffs[ , 1]^2 + diffs[ , 2]^2) #Euclidean distance

xyplot(signal ~ dist | factor(mac) + factor(angle), 
       data = offlineSummary, pch = 19, cex = 0.3,
       xlab ="distance")

#pdf(file="Geo_ScatterSignalDist.pdf", width = 7, height = 10)
oldPar = par(mar = c(3.1, 3.1, 1, 1))
library(lattice)
xyplot(signal ~ dist | factor(mac) + factor(angle), 
       data = offlineSummary, pch = 19, cex = 0.3,
       xlab ="distance")
par(oldPar)
#dev.off()
```
As we look at the plots up and down, the angle changes and from left to right the location changes. We can see that as we get further from the emitter device we see a decrease in signal strength. In conclusion, the
plots show a rather obvious down-to-the-right signal strength. 

End of EDA
```
```{r}
macs = unique(offlineSummary$mac)
online = readData('http://rdatasciencecases.org/Data/online.final.trace.txt', subMacs = macs)

online$posXY = paste(online$posX, online$posY, sep = "-")

length(unique(online$posXY))

tabonlineXYA = table(online$posXY, online$angle)
tabonlineXYA[1:6, ]
```

```{r}
keepVars = c("posXY", "posX","posY", "orientation", "angle")
byLoc = with(online, 
             by(online, list(posXY), 
                function(x) {
                  ans = x[1, keepVars]
                  avgSS = tapply(x$signal, x$mac, mean)
                  y = matrix(avgSS, nrow = 1, ncol = 6,
                        dimnames = list(ans$posXY, names(avgSS)))
                  cbind(ans, y)
                }))

onlineSummary = do.call("rbind", byLoc)  

dim(onlineSummary)

names(onlineSummary)
m = 3; angleNewObs = 230
refs = seq(0, by = 45, length  = 8)
nearestAngle = roundOrientation(angleNewObs)
  
if (m %% 2 == 1) {
  angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
} else {
  m = m + 1
  angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
  if (sign(angleNewObs - nearestAngle) > -1) 
    angles = angles[ -1 ]
  else 
    angles = angles[ -m ]
}
angles = angles + nearestAngle
angles[angles < 0] = angles[ angles < 0 ] + 360
angles[angles > 360] = angles[ angles > 360 ] - 360

offlineSubset = 
  offlineSummary[ offlineSummary$angle %in% angles, ]

reshapeSS = function(data, varSignal = "signal", 
                     keepVars = c("posXY", "posX","posY")) {
  byLocation =
    with(data, by(data, list(posXY), 
                  function(x) {
                    ans = x[1, keepVars]
                    avgSS = tapply(x[ , varSignal ], x$mac, mean)
                    y = matrix(avgSS, nrow = 1, ncol = 6,
                               dimnames = list(ans$posXY,
                                               names(avgSS)))
                    cbind(ans, y)
                  }))

  newDataSS = do.call("rbind", byLocation)
  return(newDataSS)
}

trainSS = reshapeSS(offlineSubset, varSignal = "avgSignal")

selectTrain = function(angleNewObs, signals = NULL, m = 1){
  # m is the number of angles to keep between 1 and 5
  refs = seq(0, by = 45, length  = 8)
  nearestAngle = roundOrientation(angleNewObs)
  
  if (m %% 2 == 1) 
    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
  else {
    m = m + 1
    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
    if (sign(angleNewObs - nearestAngle) > -1) 
      angles = angles[ -1 ]
    else 
      angles = angles[ -m ]
  }
  angles = angles + nearestAngle
  angles[angles < 0] = angles[ angles < 0 ] + 360
  angles[angles > 360] = angles[ angles > 360 ] - 360
  angles = sort(angles) 
  
  offlineSubset = signals[ signals$angle %in% angles, ]
  reshapeSS(offlineSubset, varSignal = "avgSignal")
}

train130 = selectTrain(130, offlineSummary, m = 3)

head(train130)

length(train130[[1]]) #Number of points that have data


```
#Finding te Nearest Neighbors
We now have our training data that can be used to predict a new point. We create the findNN() function to find the locations in the training data that have signal strengths close to a test observation.
```{r}
findNN = function(newSignal, trainSubset) {
  diffs = apply(trainSubset[ , 4:9], 1, 
                function(x) x - newSignal)
  dists = apply(diffs, 2, function(x) sqrt(sum(x^2)) )
  closest = order(dists)
  return(trainSubset[closest, 1:3 ])
}
```
Now we can make our predictions for all of our test data using th predXY() function

```{R}
predXY = function(newSignals, newAngles, trainData, 
                  numAngles = 1, k = 3){
  
  closeXY = list(length = nrow(newSignals))
  
  for (i in 1:nrow(newSignals)) {
    trainSS = selectTrain(newAngles[i], trainData, m = numAngles)
    closeXY[[i]] = 
      findNN(newSignal = as.numeric(newSignals[i, ]), trainSS)
  }

  estXY = lapply(closeXY, 
                 function(x) sapply(x[ , 2:3], 
                                    function(x) mean(x[1:k])))
  estXY = do.call("rbind", estXY)
  return(estXY)
}
```
We first test our functions with 3 nearest neighbors and 1 nearest neighbors
```{R}
estXYk3 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 3)

estXYk1 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 1)

floorErrorMap = function(estXY, actualXY, trainPoints = NULL, AP = NULL){
  
    plot(0, 0, xlim = c(0, 35), ylim = c(-3, 15), type = "n",
         xlab = "", ylab = "", axes = FALSE)
    box()
    if ( !is.null(AP) ) points(AP, pch = 15)
    if ( !is.null(trainPoints) )
      points(trainPoints, pch = 19, col="grey", cex = 0.6)
    
    points(x = actualXY[, 1], y = actualXY[, 2], 
           pch = 19, cex = 0.8 )
    points(x = estXY[, 1], y = estXY[, 2], 
           pch = 8, cex = 0.8 )
    segments(x0 = estXY[, 1], y0 = estXY[, 2],
             x1 = actualXY[, 1], y1 = actualXY[ , 2],
             lwd = 2, col = "red")
}

trainPoints = offlineSummary[ offlineSummary$angle == 0 & 
                              offlineSummary$mac == "00:0f:a3:39:e1:c0" ,
                        c("posX", "posY")]

#pdf(file="GEO_FloorPlanK3Errors.pdf", width = 10, height = 7)
oldPar = par(mar = c(1, 1, 1, 1))
floorErrorMap(estXYk3, onlineSummary[ , c("posX","posY")], 
              trainPoints = trainPoints, AP = AP)
par(oldPar)
#dev.off()

#pdf(file="GEO_FloorPlanK1Errors.pdf", width = 10, height = 7)
oldPar = par(mar = c(1, 1, 1, 1))
floorErrorMap(estXYk1, onlineSummary[ , c("posX","posY")], 
              trainPoints = trainPoints, AP = AP)
par(oldPar)
#dev.off()
```

# Q12: Use k=2 and k=5
For this exercise we will predict location using a weighted average, where the weights are inversely proportional to the distance(in signal strength) from the test observation. We will use k=2 and k=5

#k=2
```{R}
estXYk2 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 2)

oldPar = par(mar = c(1, 1, 1, 1))
floorErrorMap(estXYk2, onlineSummary[ , c("posX","posY")], 
              trainPoints = trainPoints, AP = AP)
par(oldPar)   
```
#k=5
```{R}
estXYk5 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 5)

oldPar = par(mar = c(1, 1, 1, 1))
floorErrorMap(estXYk5, onlineSummary[ , c("posX","posY")], 
              trainPoints = trainPoints, AP = AP)
par(oldPar)         
```
We can find the sum of squared error with our calcError function

```{r}
calcError = 
function(estXY, actualXY) 
   sum( rowSums( (estXY - actualXY)^2) )

actualXY = onlineSummary[ , c("posX", "posY")]
sapply(list(estXYk1, estXYk3, estXYk2, estXYk5 ), calcError, actualXY)   
```                 
#Q12 CalcError Analysis and Results
The calcError function shows that k=3 and k=5 nearest neighbor does the best job in predicting location due to having the smallest error compared to k=1 and k=2
```{r}
v = 11
permuteLocs = sample(unique(offlineSummary$posXY))
permuteLocs = matrix(permuteLocs, ncol = v, 
                     nrow = floor(length(permuteLocs)/v))

onlineFold = subset(offlineSummary, posXY %in% permuteLocs[ , 1])

reshapeSS = function(data, varSignal = "signal", 
                     keepVars = c("posXY", "posX","posY"),
                     sampleAngle = FALSE, 
                     refs = seq(0, 315, by = 45)) {
  byLocation =
    with(data, by(data, list(posXY), 
                  function(x) {
                    if (sampleAngle) {
                      x = x[x$angle == sample(refs, size = 1), ]}
                    ans = x[1, keepVars]
                    avgSS = tapply(x[ , varSignal ], x$mac, mean)
                    y = matrix(avgSS, nrow = 1, ncol = 6,
                               dimnames = list(ans$posXY,
                                               names(avgSS)))
                    cbind(ans, y)
                  }))

  newDataSS = do.call("rbind", byLocation)
  return(newDataSS)
}

offline = offline[ offline$mac != "00:0f:a3:39:dd:cd", ]

keepVars = c("posXY", "posX","posY", "orientation", "angle")

onlineCVSummary = reshapeSS(offline, keepVars = keepVars, 
                            sampleAngle = TRUE)

onlineFold = subset(onlineCVSummary, 
                    posXY %in% permuteLocs[ , 1])

offlineFold = subset(offlineSummary,
                     posXY %in% permuteLocs[ , -1])

estFold = predXY(newSignals = onlineFold[ , 6:11], 
                 newAngles = onlineFold[ , 4], 
                 offlineFold, numAngles = 3, k = 3)

actualFold = onlineFold[ , c("posX", "posY")]
calcError(estFold, actualFold)
```
k=5
```{R}
K = 20
err = rep(0, K)

for (j in 1:v) {
  onlineFold = subset(onlineCVSummary, 
                      posXY %in% permuteLocs[ , j])
  offlineFold = subset(offlineSummary,
                       posXY %in% permuteLocs[ , -j])
  actualFold = onlineFold[ , c("posX", "posY")]
  
  for (k in 1:K) {
    estFold = predXY(newSignals = onlineFold[ , 6:11],
                     newAngles = onlineFold[ , 4], 
                     offlineFold, numAngles = 3, k = k)
    err[k] = err[k] + calcError(estFold, actualFold)
  }
}

#pdf(file = "Geo_CVChoiceOfK.pdf", width = 10, height = 6)
oldPar = par(mar = c(4, 3, 1, 1))
plot(y = err, x = (1:K),  type = "l", lwd= 2,
     ylim = c(1200, 2100),
     xlab = "Number of Neighbors",
     ylab = "Sum of Square Errors")

rmseMin = min(err)
kMin = which(err == rmseMin)[1]
segments(x0 = 0, x1 = kMin, y0 = rmseMin, col = gray(0.4), 
         lty = 2, lwd = 2)
segments(x0 = kMin, x1 = kMin, y0 = 1100,  y1 = rmseMin, 
         col = grey(0.4), lty = 2, lwd = 2)

#mtext(kMin, side = 1, line = 1, at = kMin, col = grey(0.4))
text(x = kMin - 2, y = rmseMin + 40, 
     label = as.character(round(rmseMin)), col = grey(0.4))
par(oldPar)
#dev.off()

estXYk5 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 5)

calcError(estXYk5, actualXY)

predXY = function(newSignals, newAngles, trainData, 
                  numAngles = 1, k = 3){
  
  closeXY = list(length = nrow(newSignals))
  
  for (i in 1:nrow(newSignals)) {
    trainSS = selectTrain(newAngles[i], trainData, m = numAngles)
    closeXY[[i]] = findNN(newSignal = as.numeric(newSignals[i, ]),
                           trainSS)
  }

  estXY = lapply(closeXY, function(x)
                            sapply(x[ , 2:3], 
                                    function(x) mean(x[1:k])))
  estXY = do.call("rbind", estXY)
  return(estXY)
}
```



